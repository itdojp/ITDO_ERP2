"""
ERP Real-time Performance Tests
ERPãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

48æ™‚é–“ä»¥å†…å®Ÿè£… - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¥­å‹™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
- å•†å“æ¤œç´¢ <100ms
- åœ¨åº«æ›´æ–° <50ms  
- 100+ åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
"""
import pytest
import asyncio
import time
import threading
import queue
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from fastapi.testclient import TestClient
from typing import List, Dict, Any, Tuple
import json
from datetime import datetime, timedelta

from app.main import app
from app.core.database import get_db


client = TestClient(app)

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶
REALTIME_REQUIREMENTS = {
    "product_search_max_ms": 100,      # å•†å“æ¤œç´¢ 100msä»¥å†…
    "inventory_update_max_ms": 50,     # åœ¨åº«æ›´æ–° 50msä»¥å†…
    "api_response_max_ms": 200,        # APIå¿œç­” 200msä»¥å†…
    "concurrent_users_target": 100,    # 100åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼
    "throughput_min_rps": 500,         # æœ€å°ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 500 RPS
    "error_rate_max_percent": 1.0,     # ã‚¨ãƒ©ãƒ¼ç‡ 1%ä»¥ä¸‹
}


@pytest.fixture(scope="function")
def realtime_performance_db():
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker
    from app.models.base import Base
    
    engine = create_engine(
        "sqlite:///:memory:",
        echo=False,
        pool_pre_ping=True,
        connect_args={
            "check_same_thread": False,
            "timeout": 30
        }
    )
    TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    
    Base.metadata.create_all(bind=engine)
    
    def override_get_db():
        try:
            db = TestingSessionLocal()
            yield db
        finally:
            db.close()
    
    app.dependency_overrides[get_db] = override_get_db
    
    db = TestingSessionLocal()
    yield db
    db.close()
    
    app.dependency_overrides.clear()


class RealtimePerformanceMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"""
    
    def __init__(self):
        self.metrics = {
            "response_times": [],
            "throughput_data": [],
            "error_count": 0,
            "total_requests": 0,
            "start_time": None,
            "end_time": None
        }
        self.is_monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        self.is_monitoring = True
        self.metrics["start_time"] = time.time()
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.is_monitoring = False
        self.metrics["end_time"] = time.time()
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def record_request(self, response_time: float, success: bool):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨˜éŒ²"""
        self.metrics["response_times"].append(response_time)
        self.metrics["total_requests"] += 1
        if not success:
            self.metrics["error_count"] += 1
    
    def _monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.is_monitoring:
            current_time = time.time()
            
            # ç›´è¿‘1ç§’é–“ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—
            recent_requests = [
                t for t in self.metrics["response_times"]
                if current_time - t < 1.0
            ]
            
            throughput = len(recent_requests)
            self.metrics["throughput_data"].append({
                "timestamp": current_time,
                "rps": throughput
            })
            
            time.sleep(0.1)  # 100msé–“éš”ã§ç›£è¦–
    
    def get_statistics(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±å–å¾—"""
        if not self.metrics["response_times"]:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãªã—"}
        
        response_times = self.metrics["response_times"]
        duration = self.metrics["end_time"] - self.metrics["start_time"]
        
        return {
            "duration_seconds": duration,
            "total_requests": self.metrics["total_requests"],
            "error_count": self.metrics["error_count"],
            "error_rate_percent": (self.metrics["error_count"] / self.metrics["total_requests"]) * 100,
            "avg_response_time_ms": statistics.mean(response_times) * 1000,
            "min_response_time_ms": min(response_times) * 1000,
            "max_response_time_ms": max(response_times) * 1000,
            "p95_response_time_ms": statistics.quantiles(response_times, n=20)[18] * 1000,  # 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
            "p99_response_time_ms": statistics.quantiles(response_times, n=100)[98] * 1000,  # 99ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
            "average_throughput_rps": self.metrics["total_requests"] / duration,
            "peak_throughput_rps": max([d["rps"] for d in self.metrics["throughput_data"]], default=0)
        }


class TestERPRealtimePerformance:
    """ERPãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    def test_product_search_realtime_performance(self, realtime_performance_db):
        """å•†å“æ¤œç´¢ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (<100ms)"""
        print("\n=== å•†å“æ¤œç´¢ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        self._create_test_products(500)
        
        monitor = RealtimePerformanceMonitor()
        monitor.start_monitoring()
        
        # æ§˜ã€…ãªæ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ†ã‚¹ãƒˆ
        search_patterns = [
            {"limit": 10},
            {"limit": 20},
            {"search": "ãƒ†ã‚¹ãƒˆ", "limit": 15},
            {"category": "electronics", "limit": 25},
            {"min_price": 1000, "max_price": 2000, "limit": 30},
        ]
        
        failed_requests = []
        
        for i in range(100):  # 100å›ã®æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            pattern = search_patterns[i % len(search_patterns)]
            
            start_time = time.time()
            try:
                response = client.get("/api/v1/products", params=pattern)
                response_time = time.time() - start_time
                success = response.status_code == 200
                
                monitor.record_request(response_time, success)
                
                # å€‹åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ãƒã‚§ãƒƒã‚¯
                response_time_ms = response_time * 1000
                if response_time_ms > REALTIME_REQUIREMENTS["product_search_max_ms"]:
                    failed_requests.append({
                        "pattern": pattern,
                        "response_time_ms": response_time_ms,
                        "requirement_ms": REALTIME_REQUIREMENTS["product_search_max_ms"]
                    })
                
            except Exception as e:
                monitor.record_request(0.0, False)
                failed_requests.append({
                    "pattern": pattern,
                    "error": str(e)
                })
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ä»¶ã®ãŸã‚çŸ­ã„é–“éš”
            time.sleep(0.01)
        
        monitor.stop_monitoring()
        stats = monitor.get_statistics()
        
        # çµæœæ¤œè¨¼
        assert stats["avg_response_time_ms"] < REALTIME_REQUIREMENTS["product_search_max_ms"], \
            f"å¹³å‡å¿œç­”æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {stats['avg_response_time_ms']:.1f}ms > {REALTIME_REQUIREMENTS['product_search_max_ms']}ms"
        
        assert stats["p95_response_time_ms"] < REALTIME_REQUIREMENTS["product_search_max_ms"] * 1.5, \
            f"95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å¿œç­”æ™‚é–“ãŒè¦ä»¶ã‚’å¤§å¹…è¶…é: {stats['p95_response_time_ms']:.1f}ms"
        
        assert stats["error_rate_percent"] < REALTIME_REQUIREMENTS["error_rate_max_percent"], \
            f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {stats['error_rate_percent']:.2f}% > {REALTIME_REQUIREMENTS['error_rate_max_percent']}%"
        
        print(f"âœ… å•†å“æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ:")
        print(f"   å¹³å‡å¿œç­”æ™‚é–“: {stats['avg_response_time_ms']:.1f}ms (è¦ä»¶: {REALTIME_REQUIREMENTS['product_search_max_ms']}ms)")
        print(f"   95%ã‚¿ã‚¤ãƒ«å¿œç­”æ™‚é–“: {stats['p95_response_time_ms']:.1f}ms")
        print(f"   99%ã‚¿ã‚¤ãƒ«å¿œç­”æ™‚é–“: {stats['p99_response_time_ms']:.1f}ms")
        print(f"   ã‚¨ãƒ©ãƒ¼ç‡: {stats['error_rate_percent']:.2f}%")
        print(f"   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {stats['average_throughput_rps']:.1f} RPS")
        
        if failed_requests:
            print(f"âš ï¸ {len(failed_requests)}ä»¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶é•å")
    
    def test_inventory_update_realtime_performance(self, realtime_performance_db):
        """åœ¨åº«æ›´æ–°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (<50ms)"""
        print("\n=== åœ¨åº«æ›´æ–°ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ†ã‚¹ãƒˆå•†å“ä½œæˆ
        test_products = self._create_test_products(50)
        
        # åˆæœŸåœ¨åº«è¨­å®š
        for product in test_products:
            client.post(f"/api/v1/inventory/add/{product['id']}", 
                       json={"quantity": 1000, "reason": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆåˆæœŸåœ¨åº«"})
        
        monitor = RealtimePerformanceMonitor()
        monitor.start_monitoring()
        
        failed_updates = []
        
        # åœ¨åº«æ›´æ–°æ“ä½œã®ãƒ†ã‚¹ãƒˆ
        for i in range(200):  # 200å›ã®æ›´æ–°ãƒ†ã‚¹ãƒˆ
            product = test_products[i % len(test_products)]
            operation_type = ["add", "adjust", "level"][i % 3]
            
            start_time = time.time()
            try:
                if operation_type == "add":
                    response = client.post(f"/api/v1/inventory/add/{product['id']}", 
                                         json={"quantity": 10, "reason": f"ãƒ†ã‚¹ãƒˆè¿½åŠ {i}"})
                elif operation_type == "adjust":
                    response = client.post(f"/api/v1/inventory/adjust/{product['id']}", 
                                         params={"quantity": -1, "reason": f"ãƒ†ã‚¹ãƒˆèª¿æ•´{i}"})
                elif operation_type == "level":
                    response = client.get(f"/api/v1/inventory/level/{product['id']}")
                
                response_time = time.time() - start_time
                success = response.status_code in [200, 201]
                
                monitor.record_request(response_time, success)
                
                # å€‹åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ãƒã‚§ãƒƒã‚¯
                response_time_ms = response_time * 1000
                if response_time_ms > REALTIME_REQUIREMENTS["inventory_update_max_ms"]:
                    failed_updates.append({
                        "product_id": product['id'],
                        "operation": operation_type,
                        "response_time_ms": response_time_ms,
                        "requirement_ms": REALTIME_REQUIREMENTS["inventory_update_max_ms"]
                    })
                
            except Exception as e:
                monitor.record_request(0.0, False)
                failed_updates.append({
                    "product_id": product['id'],
                    "operation": operation_type,
                    "error": str(e)
                })
            
            # é«˜é »åº¦æ›´æ–°ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            time.sleep(0.005)  # 5msé–“éš”
        
        monitor.stop_monitoring()
        stats = monitor.get_statistics()
        
        # çµæœæ¤œè¨¼
        assert stats["avg_response_time_ms"] < REALTIME_REQUIREMENTS["inventory_update_max_ms"], \
            f"å¹³å‡å¿œç­”æ™‚é–“ãŒè¦ä»¶ã‚’è¶…é: {stats['avg_response_time_ms']:.1f}ms > {REALTIME_REQUIREMENTS['inventory_update_max_ms']}ms"
        
        assert stats["p95_response_time_ms"] < REALTIME_REQUIREMENTS["inventory_update_max_ms"] * 2, \
            f"95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å¿œç­”æ™‚é–“ãŒè¦ä»¶ã‚’å¤§å¹…è¶…é: {stats['p95_response_time_ms']:.1f}ms"
        
        assert stats["error_rate_percent"] < REALTIME_REQUIREMENTS["error_rate_max_percent"], \
            f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {stats['error_rate_percent']:.2f}% > {REALTIME_REQUIREMENTS['error_rate_max_percent']}%"
        
        print(f"âœ… åœ¨åº«æ›´æ–°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ:")
        print(f"   å¹³å‡å¿œç­”æ™‚é–“: {stats['avg_response_time_ms']:.1f}ms (è¦ä»¶: {REALTIME_REQUIREMENTS['inventory_update_max_ms']}ms)")
        print(f"   95%ã‚¿ã‚¤ãƒ«å¿œç­”æ™‚é–“: {stats['p95_response_time_ms']:.1f}ms")
        print(f"   ã‚¨ãƒ©ãƒ¼ç‡: {stats['error_rate_percent']:.2f}%")
        print(f"   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {stats['average_throughput_rps']:.1f} RPS")
        
        if failed_updates:
            print(f"âš ï¸ {len(failed_updates)}ä»¶ã®åœ¨åº«æ›´æ–°è¦ä»¶é•å")
    
    def test_concurrent_users_realtime_performance(self, realtime_performance_db):
        """åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (100+ãƒ¦ãƒ¼ã‚¶ãƒ¼)"""
        print("\n=== åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        test_products = self._create_test_products(100)
        
        # åœ¨åº«è¨­å®š
        for product in test_products:
            client.post(f"/api/v1/inventory/add/{product['id']}", 
                       json={"quantity": 10000, "reason": "åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆç”¨"})
        
        def simulate_realtime_user(user_id: int, duration_seconds: int = 30) -> Dict[str, Any]:
            """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
            user_monitor = RealtimePerformanceMonitor()
            user_monitor.start_monitoring()
            
            end_time = time.time() + duration_seconds
            operations_performed = 0
            
            try:
                while time.time() < end_time:
                    # ãƒ©ãƒ³ãƒ€ãƒ ãªæ¥­å‹™æ“ä½œ
                    operation = ["search", "detail", "inventory", "order"][operations_performed % 4]
                    
                    start_time = time.time()
                    success = False
                    
                    try:
                        if operation == "search":
                            response = client.get("/api/v1/products", 
                                                params={"limit": 20, "search": f"ãƒ†ã‚¹ãƒˆ{user_id}"})
                            success = response.status_code == 200
                            
                        elif operation == "detail":
                            product = test_products[operations_performed % len(test_products)]
                            response = client.get(f"/api/v1/products/{product['id']}")
                            success = response.status_code == 200
                            
                        elif operation == "inventory":
                            product = test_products[operations_performed % len(test_products)]
                            response = client.get(f"/api/v1/inventory/level/{product['id']}")
                            success = response.status_code == 200
                            
                        elif operation == "order":
                            product = test_products[operations_performed % len(test_products)]
                            order_data = {
                                "customer_name": f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼{user_id}",
                                "customer_email": f"realtime{user_id}@test.com",
                                "items": [
                                    {
                                        "product_id": product["id"],
                                        "quantity": 1,
                                        "unit_price": product["price"]
                                    }
                                ]
                            }
                            response = client.post("/api/v1/sales-orders", json=order_data)
                            success = response.status_code == 201
                    
                    except Exception:
                        success = False
                    
                    response_time = time.time() - start_time
                    user_monitor.record_request(response_time, success)
                    operations_performed += 1
                    
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ“ä½œé–“éš”ï¼ˆå®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•ï¼‰
                    time.sleep(0.1 + (user_id % 10) * 0.01)  # 100-200msé–“éš”
                
                user_monitor.stop_monitoring()
                user_stats = user_monitor.get_statistics()
                
                return {
                    "user_id": user_id,
                    "operations_performed": operations_performed,
                    "success": True,
                    "stats": user_stats
                }
                
            except Exception as e:
                user_monitor.stop_monitoring()
                return {
                    "user_id": user_id,
                    "operations_performed": operations_performed,
                    "success": False,
                    "error": str(e)
                }
        
        # åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å®Ÿè¡Œ
        concurrent_users = REALTIME_REQUIREMENTS["concurrent_users_target"]
        test_duration = 30  # 30ç§’é–“ã®ãƒ†ã‚¹ãƒˆ
        
        print(f"ğŸš€ {concurrent_users}åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã®{test_duration}ç§’é–“è² è·ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [
                executor.submit(simulate_realtime_user, user_id, test_duration)
                for user_id in range(concurrent_users)
            ]
            
            user_results = []
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=test_duration + 10)
                    user_results.append(result)
                except Exception as e:
                    user_results.append({
                        "success": False,
                        "error": str(e),
                        "user_id": -1
                    })
        
        total_time = time.time() - start_time
        
        # çµæœåˆ†æ
        successful_users = [r for r in user_results if r["success"]]
        failed_users = [r for r in user_results if not r["success"]]
        
        success_rate = len(successful_users) / len(user_results) * 100
        total_operations = sum(r.get("operations_performed", 0) for r in successful_users)
        
        # å…¨ä½“çµ±è¨ˆè¨ˆç®—
        all_response_times = []
        total_errors = 0
        total_requests = 0
        
        for user_result in successful_users:
            if "stats" in user_result:
                stats = user_result["stats"]
                if "response_times" in stats:
                    all_response_times.extend(stats["response_times"])
                total_errors += stats.get("error_count", 0)
                total_requests += stats.get("total_requests", 0)
        
        if all_response_times:
            overall_avg_response_ms = statistics.mean(all_response_times) * 1000
            overall_p95_response_ms = statistics.quantiles(all_response_times, n=20)[18] * 1000
        else:
            overall_avg_response_ms = 0
            overall_p95_response_ms = 0
        
        overall_error_rate = (total_errors / total_requests * 100) if total_requests > 0 else 0
        overall_throughput = total_operations / total_time
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶æ¤œè¨¼
        assert success_rate >= 95.0, f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æˆåŠŸç‡ãŒä½ã™ãã¾ã™: {success_rate:.1f}% < 95%"
        assert len(successful_users) >= concurrent_users * 0.9, \
            f"æˆåŠŸãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãŒä¸ååˆ†: {len(successful_users)} < {concurrent_users * 0.9}"
        assert overall_error_rate < REALTIME_REQUIREMENTS["error_rate_max_percent"], \
            f"å…¨ä½“ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {overall_error_rate:.2f}%"
        assert overall_throughput >= REALTIME_REQUIREMENTS["throughput_min_rps"] * 0.5, \
            f"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒä½ã™ãã¾ã™: {overall_throughput:.1f} < {REALTIME_REQUIREMENTS['throughput_min_rps'] * 0.5}"
        
        print(f"âœ… åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ:")
        print(f"   å®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {concurrent_users}")
        print(f"   æˆåŠŸãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(successful_users)}")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"   ç·æ“ä½œæ•°: {total_operations}")
        print(f"   å¹³å‡å¿œç­”æ™‚é–“: {overall_avg_response_ms:.1f}ms")
        print(f"   95%ã‚¿ã‚¤ãƒ«å¿œç­”æ™‚é–“: {overall_p95_response_ms:.1f}ms")
        print(f"   å…¨ä½“ã‚¨ãƒ©ãƒ¼ç‡: {overall_error_rate:.2f}%")
        print(f"   å…¨ä½“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {overall_throughput:.1f} RPS")
        print(f"   ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“: {total_time:.1f}ç§’")
        
        return {
            "concurrent_users": concurrent_users,
            "successful_users": len(successful_users),
            "success_rate": success_rate,
            "total_operations": total_operations,
            "avg_response_time_ms": overall_avg_response_ms,
            "error_rate": overall_error_rate,
            "throughput_rps": overall_throughput
        }
    
    def _create_test_products(self, count: int) -> List[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆå•†å“ä½œæˆ"""
        products = []
        
        for i in range(count):
            product_data = {
                "code": f"REALTIME-{i:04d}",
                "name": f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚¹ãƒˆå•†å“ {i}",
                "description": f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨å•†å“ {i}",
                "price": 1000.0 + (i * 10),
                "cost": 600.0 + (i * 6),
                "category": f"category{i % 10}",
                "unit": "å€‹",
                "status": "active"
            }
            
            try:
                response = client.post("/api/v1/products", json=product_data)
                if response.status_code == 201:
                    products.append(response.json())
            except Exception:
                pass  # ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ã—ã¦ç¶™ç¶š
        
        return products


class TestERPStressTestRealtime:
    """ERPã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰"""
    
    def test_spike_load_handling(self, realtime_performance_db):
        """ã‚¹ãƒ‘ã‚¤ã‚¯è² è·å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        print("\n=== ã‚¹ãƒ‘ã‚¤ã‚¯è² è·å‡¦ç†ãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šï¼ˆè»½è² è·ï¼‰
        baseline_results = self._measure_baseline_performance()
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯è² è·å®Ÿè¡Œï¼ˆé‡è² è·ï¼‰
        spike_results = self._execute_spike_load()
        
        # å›å¾©æ¸¬å®šï¼ˆè»½è² è·ã«æˆ»ã‚‹ï¼‰
        recovery_results = self._measure_recovery_performance()
        
        # çµæœæ¯”è¼ƒãƒ»æ¤œè¨¼
        print(f"ğŸ“Š ã‚¹ãƒ‘ã‚¤ã‚¯è² è·ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å¿œç­”æ™‚é–“: {baseline_results['avg_response_ms']:.1f}ms")
        print(f"   ã‚¹ãƒ‘ã‚¤ã‚¯è² è·å¿œç­”æ™‚é–“: {spike_results['avg_response_ms']:.1f}ms")
        print(f"   å›å¾©å¾Œå¿œç­”æ™‚é–“: {recovery_results['avg_response_ms']:.1f}ms")
        
        # å›å¾©æ€§èƒ½ã®ç¢ºèª
        recovery_ratio = recovery_results['avg_response_ms'] / baseline_results['avg_response_ms']
        assert recovery_ratio < 1.5, f"ã‚·ã‚¹ãƒ†ãƒ å›å¾©ãŒä¸ååˆ†ã§ã™: {recovery_ratio:.2f}x"
        
        print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ å›å¾©ç‡: {recovery_ratio:.2f}x (1.5xä»¥ä¸‹ãŒè¦ä»¶)")
    
    def _measure_baseline_performance(self) -> Dict[str, float]:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½æ¸¬å®š"""
        monitor = RealtimePerformanceMonitor()
        monitor.start_monitoring()
        
        # è»½è² è·ã§ã®æ¸¬å®š
        for i in range(50):
            response = client.get("/api/v1/products", params={"limit": 10})
            monitor.record_request(0.1, response.status_code == 200)  # ä»®ã®å¿œç­”æ™‚é–“
            time.sleep(0.1)
        
        monitor.stop_monitoring()
        stats = monitor.get_statistics()
        
        return {
            "avg_response_ms": stats.get("avg_response_time_ms", 0),
            "throughput_rps": stats.get("average_throughput_rps", 0)
        }
    
    def _execute_spike_load(self) -> Dict[str, float]:
        """ã‚¹ãƒ‘ã‚¤ã‚¯è² è·å®Ÿè¡Œ"""
        monitor = RealtimePerformanceMonitor()
        monitor.start_monitoring()
        
        # é«˜è² è·ï¼ˆ200åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
        def spike_request():
            response = client.get("/api/v1/products", params={"limit": 50})
            return response.status_code == 200
        
        with ThreadPoolExecutor(max_workers=200) as executor:
            futures = [executor.submit(spike_request) for _ in range(200)]
            results = [f.result() for f in as_completed(futures)]
        
        monitor.stop_monitoring()
        stats = monitor.get_statistics()
        
        return {
            "avg_response_ms": stats.get("avg_response_time_ms", 0),
            "success_rate": sum(results) / len(results) * 100
        }
    
    def _measure_recovery_performance(self) -> Dict[str, float]:
        """å›å¾©æ€§èƒ½æ¸¬å®š"""
        # ã‚¹ãƒ‘ã‚¤ã‚¯è² è·å¾Œã®å›å¾©æ¸¬å®š
        time.sleep(2)  # 2ç§’é–“ã®å›å¾©æ™‚é–“
        
        return self._measure_baseline_performance()


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short", "-s"])