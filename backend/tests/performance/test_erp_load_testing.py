"""
ERP Load Testing Suite
ERPè² è·ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

48æ™‚é–“ä»¥å†…å®Ÿè£… - å¤§è¦æ¨¡è² è·ãƒ†ã‚¹ãƒˆ
- é•·æ™‚é–“è² è·ãƒ†ã‚¹ãƒˆ
- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è² è·ãƒ†ã‚¹ãƒˆ
- ã‚·ã‚¹ãƒ†ãƒ é™ç•Œãƒ†ã‚¹ãƒˆ
"""
import pytest
import time
import threading
import psutil
import gc
from concurrent.futures import ThreadPoolExecutor, as_completed
from fastapi.testclient import TestClient
from typing import List, Dict, Any
import statistics
import json
from datetime import datetime, timedelta

from app.main import app
from app.core.database import get_db


client = TestClient(app)

# è² è·ãƒ†ã‚¹ãƒˆè¨­å®š
LOAD_TEST_CONFIG = {
    "long_duration_minutes": 5,        # é•·æ™‚é–“ãƒ†ã‚¹ãƒˆï¼ˆæœ¬ç•ªã§ã¯60åˆ†ï¼‰
    "max_concurrent_users": 200,       # æœ€å¤§åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼
    "ramp_up_seconds": 30,            # ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—æ™‚é–“
    "sustained_load_minutes": 2,       # æŒç¶šè² è·æ™‚é–“
    "memory_leak_threshold_mb": 100,   # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é–¾å€¤
    "database_connection_limit": 50,   # DBæ¥ç¶šä¸Šé™
}


@pytest.fixture(scope="function")
def load_test_db():
    """è² è·ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker
    from app.models.base import Base
    
    # ã‚ˆã‚Šé«˜æ€§èƒ½ãªè¨­å®š
    engine = create_engine(
        "sqlite:///:memory:",
        echo=False,
        pool_size=20,
        max_overflow=30,
        pool_pre_ping=True,
        connect_args={
            "check_same_thread": False,
            "timeout": 60,
            "cached_statements": 100
        }
    )
    
    TestingSessionLocal = sessionmaker(
        autocommit=False, 
        autoflush=False, 
        bind=engine
    )
    
    Base.metadata.create_all(bind=engine)
    
    def override_get_db():
        try:
            db = TestingSessionLocal()
            yield db
        finally:
            db.close()
    
    app.dependency_overrides[get_db] = override_get_db
    
    db = TestingSessionLocal()
    yield db
    db.close()
    
    app.dependency_overrides.clear()


class SystemResourceMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
    
    def __init__(self):
        self.monitoring = False
        self.metrics = {
            "cpu_usage": [],
            "memory_usage": [],
            "memory_rss_mb": [],
            "active_threads": [],
            "timestamps": []
        }
        self.monitor_thread = None
        self.process = psutil.Process()
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def _monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.monitoring:
            try:
                # CPUä½¿ç”¨ç‡
                cpu_percent = self.process.cpu_percent()
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
                memory_info = self.process.memory_info()
                memory_percent = self.process.memory_percent()
                memory_rss_mb = memory_info.rss / 1024 / 1024
                
                # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
                thread_count = self.process.num_threads()
                
                self.metrics["cpu_usage"].append(cpu_percent)
                self.metrics["memory_usage"].append(memory_percent)
                self.metrics["memory_rss_mb"].append(memory_rss_mb)
                self.metrics["active_threads"].append(thread_count)
                self.metrics["timestamps"].append(time.time())
                
            except Exception:
                pass  # ç›£è¦–ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
            
            time.sleep(1.0)  # 1ç§’é–“éš”
    
    def get_peak_metrics(self) -> Dict[str, float]:
        """ãƒ”ãƒ¼ã‚¯å€¤å–å¾—"""
        if not self.metrics["timestamps"]:
            return {}
        
        return {
            "peak_cpu_percent": max(self.metrics["cpu_usage"], default=0),
            "peak_memory_percent": max(self.metrics["memory_usage"], default=0),
            "peak_memory_rss_mb": max(self.metrics["memory_rss_mb"], default=0),
            "peak_threads": max(self.metrics["active_threads"], default=0),
            "avg_cpu_percent": statistics.mean(self.metrics["cpu_usage"]) if self.metrics["cpu_usage"] else 0,
            "avg_memory_rss_mb": statistics.mean(self.metrics["memory_rss_mb"]) if self.metrics["memory_rss_mb"] else 0,
            "monitoring_duration": self.metrics["timestamps"][-1] - self.metrics["timestamps"][0] if len(self.metrics["timestamps"]) > 1 else 0
        }
    
    def detect_memory_leak(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º"""
        if len(self.metrics["memory_rss_mb"]) < 10:
            return {"detected": False, "reason": "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"}
        
        # æœ€åˆã¨æœ€å¾Œã®10%ã®ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒ
        start_samples = int(len(self.metrics["memory_rss_mb"]) * 0.1)
        end_samples = int(len(self.metrics["memory_rss_mb"]) * 0.1)
        
        start_avg = statistics.mean(self.metrics["memory_rss_mb"][:start_samples])
        end_avg = statistics.mean(self.metrics["memory_rss_mb"][-end_samples:])
        
        memory_increase_mb = end_avg - start_avg
        increase_percent = (memory_increase_mb / start_avg) * 100 if start_avg > 0 else 0
        
        is_leak = (
            memory_increase_mb > LOAD_TEST_CONFIG["memory_leak_threshold_mb"] and
            increase_percent > 20  # 20%ä»¥ä¸Šã®å¢—åŠ 
        )
        
        return {
            "detected": is_leak,
            "memory_increase_mb": memory_increase_mb,
            "increase_percent": increase_percent,
            "start_memory_mb": start_avg,
            "end_memory_mb": end_avg
        }


class TestERPLongDurationLoad:
    """ERPé•·æ™‚é–“è² è·ãƒ†ã‚¹ãƒˆ"""
    
    def test_sustained_load_performance(self, load_test_db):
        """æŒç¶šè² è·ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        print(f"\n=== {LOAD_TEST_CONFIG['sustained_load_minutes']}åˆ†é–“æŒç¶šè² è·ãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
        test_products = self._prepare_load_test_data()
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–é–‹å§‹
        resource_monitor = SystemResourceMonitor()
        resource_monitor.start_monitoring()
        
        # æŒç¶šè² è·å®Ÿè¡Œ
        duration_seconds = LOAD_TEST_CONFIG['sustained_load_minutes'] * 60
        concurrent_users = 50  # æŒç¶šå¯èƒ½ãªãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
        
        def sustained_user_simulation(user_id: int) -> Dict[str, Any]:
            """æŒç¶šè² è·ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
            end_time = time.time() + duration_seconds
            operations = 0
            errors = 0
            response_times = []
            
            while time.time() < end_time:
                # å¤šæ§˜ãªæ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³
                operation_weights = [0.5, 0.2, 0.2, 0.1]  # æ¤œç´¢, è©³ç´°, åœ¨åº«, æ³¨æ–‡
                operation_type = ["search", "detail", "inventory", "order"][
                    self._weighted_choice(operation_weights)
                ]
                
                start_time = time.time()
                try:
                    success = self._execute_operation(operation_type, test_products, user_id)
                    response_time = time.time() - start_time
                    response_times.append(response_time)
                    
                    if not success:
                        errors += 1
                    
                    operations += 1
                    
                except Exception:
                    errors += 1
                    response_times.append(0)
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•é–“éš”ï¼ˆãƒªã‚¢ãƒ«ãªãƒšãƒ¼ã‚¹ï¼‰
                time.sleep(0.5 + (user_id % 10) * 0.1)  # 0.5-1.4ç§’é–“éš”
            
            return {
                "user_id": user_id,
                "operations": operations,
                "errors": errors,
                "avg_response_time": statistics.mean(response_times) if response_times else 0,
                "max_response_time": max(response_times) if response_times else 0
            }
        
        print(f"ğŸš€ {concurrent_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã®{duration_seconds}ç§’é–“æŒç¶šè² è·é–‹å§‹")
        start_time = time.time()
        
        # ä¸¦è¡Œå®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [
                executor.submit(sustained_user_simulation, user_id)
                for user_id in range(concurrent_users)
            ]
            
            user_results = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    user_results.append(result)
                except Exception as e:
                    user_results.append({
                        "user_id": -1,
                        "operations": 0,
                        "errors": 1,
                        "error": str(e)
                    })
        
        # ç›£è¦–åœæ­¢
        resource_monitor.stop_monitoring()
        total_duration = time.time() - start_time
        
        # çµæœåˆ†æ
        total_operations = sum(r["operations"] for r in user_results)
        total_errors = sum(r["errors"] for r in user_results)
        error_rate = (total_errors / total_operations * 100) if total_operations > 0 else 0
        throughput = total_operations / total_duration
        
        avg_response_times = [r["avg_response_time"] for r in user_results if r["avg_response_time"] > 0]
        overall_avg_response = statistics.mean(avg_response_times) if avg_response_times else 0
        
        # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç¢ºèª
        resource_metrics = resource_monitor.get_peak_metrics()
        memory_leak_analysis = resource_monitor.detect_memory_leak()
        
        # æ€§èƒ½è¦ä»¶æ¤œè¨¼
        assert error_rate < 2.0, f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {error_rate:.2f}% > 2%"
        assert overall_avg_response < 1.0, f"å¹³å‡å¿œç­”æ™‚é–“ãŒé…ã™ãã¾ã™: {overall_avg_response:.3f}s > 1s"
        assert resource_metrics["peak_memory_rss_mb"] < 500, f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã™ãã¾ã™: {resource_metrics['peak_memory_rss_mb']:.1f}MB"
        assert not memory_leak_analysis["detected"], f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: +{memory_leak_analysis['memory_increase_mb']:.1f}MB"
        
        print(f"âœ… æŒç¶šè² è·ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   å®Ÿè¡Œæ™‚é–“: {total_duration:.1f}ç§’")
        print(f"   ç·æ“ä½œæ•°: {total_operations}")
        print(f"   ã‚¨ãƒ©ãƒ¼ç‡: {error_rate:.2f}%")
        print(f"   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.1f} ops/sec")
        print(f"   å¹³å‡å¿œç­”æ™‚é–“: {overall_avg_response:.3f}ç§’")
        print(f"   ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {resource_metrics['peak_memory_rss_mb']:.1f}MB")
        print(f"   ãƒ”ãƒ¼ã‚¯CPU: {resource_metrics['peak_cpu_percent']:.1f}%")
        print(f"   ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯: {'æ¤œå‡º' if memory_leak_analysis['detected'] else 'æœªæ¤œå‡º'}")
    
    def test_ramp_up_load_testing(self, load_test_db):
        """ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—è² è·ãƒ†ã‚¹ãƒˆ"""
        print(f"\n=== ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—è² è·ãƒ†ã‚¹ãƒˆ ===")
        
        test_products = self._prepare_load_test_data()
        resource_monitor = SystemResourceMonitor()
        resource_monitor.start_monitoring()
        
        max_users = LOAD_TEST_CONFIG["max_concurrent_users"]
        ramp_up_duration = LOAD_TEST_CONFIG["ramp_up_seconds"]
        
        # æ®µéšçš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã‚’å¢—åŠ 
        user_increments = [10, 25, 50, 100, 150, 200]
        phase_results = []
        
        for phase, target_users in enumerate(user_increments):
            if target_users > max_users:
                break
                
            print(f"ğŸ“ˆ Phase {phase + 1}: {target_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼è² è·")
            
            # å„ãƒ•ã‚§ãƒ¼ã‚ºã§ã®è² è·å®Ÿè¡Œ
            phase_start = time.time()
            
            def ramp_user_simulation(user_id: int) -> Dict[str, Any]:
                """ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—æ®µéšã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
                operations = 0
                errors = 0
                
                # 10ç§’é–“ã®è² è·
                end_time = time.time() + 10
                while time.time() < end_time:
                    try:
                        success = self._execute_operation("search", test_products, user_id)
                        if not success:
                            errors += 1
                        operations += 1
                        time.sleep(0.1)  # é«˜é »åº¦æ“ä½œ
                    except Exception:
                        errors += 1
                
                return {
                    "user_id": user_id,
                    "operations": operations,
                    "errors": errors
                }
            
            # ä¸¦è¡Œå®Ÿè¡Œ
            with ThreadPoolExecutor(max_workers=target_users) as executor:
                futures = [
                    executor.submit(ramp_user_simulation, user_id)
                    for user_id in range(target_users)
                ]
                
                results = [f.result() for f in as_completed(futures)]
            
            phase_duration = time.time() - phase_start
            phase_operations = sum(r["operations"] for r in results)
            phase_errors = sum(r["errors"] for r in results)
            phase_error_rate = (phase_errors / phase_operations * 100) if phase_operations > 0 else 0
            phase_throughput = phase_operations / phase_duration
            
            phase_results.append({
                "users": target_users,
                "operations": phase_operations,
                "error_rate": phase_error_rate,
                "throughput": phase_throughput,
                "duration": phase_duration
            })
            
            print(f"   æ“ä½œæ•°: {phase_operations}, ã‚¨ãƒ©ãƒ¼ç‡: {phase_error_rate:.2f}%, ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {phase_throughput:.1f} ops/sec")
            
            # æ®µéšé–“ã®ä¼‘æ†©
            time.sleep(2)
        
        resource_monitor.stop_monitoring()
        resource_metrics = resource_monitor.get_peak_metrics()
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åˆ†æ
        throughput_degradation = self._analyze_scalability(phase_results)
        
        print(f"âœ… ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   æœ€å¤§ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {max([p['users'] for p in phase_results])}")
        print(f"   ãƒ”ãƒ¼ã‚¯ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {max([p['throughput'] for p in phase_results]):.1f} ops/sec")
        print(f"   ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åŠ¹ç‡: {throughput_degradation:.1f}% (ä½ã„æ–¹ãŒè‰¯ã„)")
        print(f"   ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ - ãƒ¡ãƒ¢ãƒª: {resource_metrics['peak_memory_rss_mb']:.1f}MB, CPU: {resource_metrics['peak_cpu_percent']:.1f}%")
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£è¦ä»¶ç¢ºèª
        assert throughput_degradation < 50, f"ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ä½ä¸‹ãŒå¤§ãã™ãã¾ã™: {throughput_degradation:.1f}%"
    
    def _prepare_load_test_data(self) -> List[Dict[str, Any]]:
        """è² è·ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        products = []
        
        for i in range(200):  # 200å•†å“
            product_data = {
                "code": f"LOAD-{i:04d}",
                "name": f"è² è·ãƒ†ã‚¹ãƒˆå•†å“ {i}",
                "price": 1000.0 + i,
                "category": f"load_category_{i % 20}",
                "status": "active"
            }
            
            try:
                response = client.post("/api/v1/products", json=product_data)
                if response.status_code == 201:
                    product = response.json()
                    products.append(product)
                    
                    # åœ¨åº«è¨­å®š
                    client.post(f"/api/v1/inventory/add/{product['id']}", 
                               json={"quantity": 1000, "reason": "è² è·ãƒ†ã‚¹ãƒˆç”¨"})
            except Exception:
                pass
        
        return products
    
    def _execute_operation(self, operation_type: str, test_products: List[Dict], user_id: int) -> bool:
        """æ“ä½œå®Ÿè¡Œ"""
        try:
            if operation_type == "search":
                response = client.get("/api/v1/products", 
                                    params={"limit": 20, "search": f"è² è·{user_id % 100}"})
                return response.status_code == 200
                
            elif operation_type == "detail" and test_products:
                product = test_products[user_id % len(test_products)]
                response = client.get(f"/api/v1/products/{product['id']}")
                return response.status_code == 200
                
            elif operation_type == "inventory" and test_products:
                product = test_products[user_id % len(test_products)]
                response = client.get(f"/api/v1/inventory/level/{product['id']}")
                return response.status_code == 200
                
            elif operation_type == "order" and test_products:
                product = test_products[user_id % len(test_products)]
                order_data = {
                    "customer_name": f"è² è·ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼{user_id}",
                    "customer_email": f"load{user_id}@test.com",
                    "items": [
                        {
                            "product_id": product["id"],
                            "quantity": 1,
                            "unit_price": product["price"]
                        }
                    ]
                }
                response = client.post("/api/v1/sales-orders", json=order_data)
                return response.status_code == 201
                
        except Exception:
            return False
        
        return False
    
    def _weighted_choice(self, weights: List[float]) -> int:
        """é‡ã¿ä»˜ãé¸æŠ"""
        import random
        r = random.random()
        cumulative = 0
        for i, weight in enumerate(weights):
            cumulative += weight
            if r <= cumulative:
                return i
        return len(weights) - 1
    
    def _analyze_scalability(self, phase_results: List[Dict]) -> float:
        """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åˆ†æ"""
        if len(phase_results) < 2:
            return 0
        
        # æœ€åˆã¨æœ€å¾Œã®ãƒ•ã‚§ãƒ¼ã‚ºã§ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆåŠ¹ç‡ã‚’æ¯”è¼ƒ
        first_phase = phase_results[0]
        last_phase = phase_results[-1]
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ãŸã‚Šã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        first_throughput_per_user = first_phase["throughput"] / first_phase["users"]
        last_throughput_per_user = last_phase["throughput"] / last_phase["users"]
        
        # åŠ¹ç‡ä½ä¸‹ç‡ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆï¼‰
        efficiency_degradation = ((first_throughput_per_user - last_throughput_per_user) / first_throughput_per_user) * 100
        
        return max(0, efficiency_degradation)


class TestERPMemoryLeakDetection:
    """ERPãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
    
    def test_memory_leak_detection(self, load_test_db):
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        print("\n=== ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ ===")
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        gc.collect()
        
        resource_monitor = SystemResourceMonitor()
        resource_monitor.start_monitoring()
        
        # å¤§é‡ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆãƒ»å‰Šé™¤ã‚’ç¹°ã‚Šè¿”ã™
        for cycle in range(10):  # 10ã‚µã‚¤ã‚¯ãƒ«
            print(f"  ã‚µã‚¤ã‚¯ãƒ« {cycle + 1}/10 å®Ÿè¡Œä¸­...")
            
            # å¤§é‡ã®å•†å“ä½œæˆ
            created_products = []
            for i in range(50):
                product_data = {
                    "code": f"MEMLEAK-{cycle}-{i:03d}",
                    "name": f"ãƒ¡ãƒ¢ãƒªãƒ†ã‚¹ãƒˆå•†å“ {cycle}-{i}",
                    "price": 1000.0,
                    "status": "active"
                }
                
                response = client.post("/api/v1/products", json=product_data)
                if response.status_code == 201:
                    created_products.append(response.json())
            
            # åœ¨åº«æ“ä½œï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¢—åŠ ï¼‰
            for product in created_products:
                client.post(f"/api/v1/inventory/add/{product['id']}", 
                           json={"quantity": 100, "reason": f"ãƒ¡ãƒ¢ãƒªãƒ†ã‚¹ãƒˆ{cycle}"})
                client.get(f"/api/v1/inventory/level/{product['id']}")
            
            # å•†å“æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨ï¼‰
            for i in range(20):
                client.get("/api/v1/products", params={"limit": 100})
            
            # æ„å›³çš„ã«ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            gc.collect()
            
            # ã‚µã‚¤ã‚¯ãƒ«é–“ã®å¾…æ©Ÿ
            time.sleep(1)
        
        resource_monitor.stop_monitoring()
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯åˆ†æ
        memory_leak_analysis = resource_monitor.detect_memory_leak()
        resource_metrics = resource_monitor.get_peak_metrics()
        
        print(f"âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºçµæœ:")
        print(f"   ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯: {'æ¤œå‡º' if memory_leak_analysis['detected'] else 'æœªæ¤œå‡º'}")
        print(f"   ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡: {memory_leak_analysis['memory_increase_mb']:.1f}MB")
        print(f"   å¢—åŠ ç‡: {memory_leak_analysis['increase_percent']:.1f}%")
        print(f"   é–‹å§‹æ™‚ãƒ¡ãƒ¢ãƒª: {memory_leak_analysis['start_memory_mb']:.1f}MB")
        print(f"   çµ‚äº†æ™‚ãƒ¡ãƒ¢ãƒª: {memory_leak_analysis['end_memory_mb']:.1f}MB")
        print(f"   ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {resource_metrics['peak_memory_rss_mb']:.1f}MB")
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è¦ä»¶æ¤œè¨¼
        assert not memory_leak_analysis["detected"], \
            f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: +{memory_leak_analysis['memory_increase_mb']:.1f}MB ({memory_leak_analysis['increase_percent']:.1f}%å¢—åŠ )"
        
        assert resource_metrics["peak_memory_rss_mb"] < 1000, \
            f"ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã™ãã¾ã™: {resource_metrics['peak_memory_rss_mb']:.1f}MB > 1000MB"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short", "-s"])